import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

# Load the datasets
train_features = pd.read_csv('C:\\Users\\Gunjan\\Downloads\\dataset and all\\training_set_features.csv')
train_labels = pd.read_csv('C:\\Users\\Gunjan\\Downloads\\dataset and all\\training_set_labels.csv')
test_data = pd.read_csv('C:\\Users\\Gunjan\\Downloads\\dataset and all\\test_set_features.csv')

# Merge the features and labels for the training set
train_data = pd.merge(train_features, train_labels, on='respondent_id')

# Preprocessing
# Identify categorical and numerical columns
categorical_cols = [
    'age_group', 'education', 'race', 'sex', 'income_poverty', 'marital_status', 
    'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa', 
    'employment_industry', 'employment_occupation'
]
numerical_cols = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()
numerical_cols.remove('respondent_id')
numerical_cols.remove('xyz_vaccine')
numerical_cols.remove('seasonal_vaccine')

# Preprocessing for numerical data
numerical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# Preprocessing for categorical data
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Bundle preprocessing for numerical and categorical data
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Split the data into features and target variables
X = train_data.drop(['xyz_vaccine', 'seasonal_vaccine'], axis=1)
y_xyz = train_data['xyz_vaccine']
y_seasonal = train_data['seasonal_vaccine']

# Split the data into training and validation sets
X_train, X_val, y_train_xyz, y_val_xyz = train_test_split(X, y_xyz, test_size=0.2, random_state=42)
_, _, y_train_seasonal, y_val_seasonal = train_test_split(X, y_seasonal, test_size=0.2, random_state=42)

# Define the model
model_xyz = Pipeline(steps=[('preprocessor', preprocessor),
                            ('classifier', LogisticRegression(max_iter=500))])

model_seasonal = Pipeline(steps=[('preprocessor', preprocessor),
                                 ('classifier', LogisticRegression(max_iter=500))])

# Train the model
model_xyz.fit(X_train, y_train_xyz)
model_seasonal.fit(X_train, y_train_seasonal)

# Make predictions on the test data
test_pred_proba_xyz = model_xyz.predict_proba(test_data)[:, 1]
test_pred_proba_seasonal = model_seasonal.predict_proba(test_data)[:, 1]

# Format the output
submission = pd.DataFrame({
    'respondent_id': test_data['respondent_id'],
    'xyz_vaccine': test_pred_proba_xyz,
    'seasonal_vaccine': test_pred_proba_seasonal
})

# Save the submission file
submission.to_csv('C:\\Users\\Gunjan\\Downloads\\submission.csv', index=False)

